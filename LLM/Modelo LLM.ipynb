{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38395,"status":"ok","timestamp":1750097470061,"user":{"displayName":"Nandoo","userId":"07661495182627101655"},"user_tz":-120},"id":"X3BaHwc3wlb3","outputId":"d0d91f7c-a06f-4bc6-ef6f-da60d5f207f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-stack\n","  Downloading llama_stack-0.2.10.1-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.11.15)\n","Requirement already satisfied: fastapi<1.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.115.12)\n","Collecting fire (from llama-stack)\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.28.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.33.0)\n","Requirement already satisfied: jinja2>=3.1.6 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.1.6)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from llama-stack) (4.24.0)\n","Collecting llama-stack-client>=0.2.10 (from llama-stack)\n","  Downloading llama_stack_client-0.2.10-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: openai>=1.66 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (1.86.0)\n","Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.0.51)\n","Collecting python-dotenv (from llama-stack)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting python-jose (from llama-stack)\n","  Downloading python_jose-3.5.0-py2.py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (2.11.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from llama-stack) (2.32.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from llama-stack) (13.9.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from llama-stack) (75.2.0)\n","Requirement already satisfied: starlette in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.46.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from llama-stack) (3.1.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.9.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from llama-stack) (11.2.1)\n","Requirement already satisfied: h11>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.16.0)\n","Requirement already satisfied: python-multipart>=0.0.20 in /usr/local/lib/python3.11/dist-packages (from llama-stack) (0.0.20)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0,>=0.115.0->llama-stack) (4.14.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.6->llama-stack) (3.0.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.10->llama-stack) (4.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.10->llama-stack) (8.2.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.10->llama-stack) (1.9.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.10->llama-stack) (2.2.2)\n","Collecting pyaml (from llama-stack-client>=0.2.10->llama-stack)\n","  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.10->llama-stack) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from llama-stack-client>=0.2.10->llama-stack) (4.67.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-stack) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-stack) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-stack) (3.10)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66->llama-stack) (0.10.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->llama-stack) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->llama-stack) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->llama-stack) (0.4.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->llama-stack) (1.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (6.0.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->llama-stack) (1.1.3)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->llama-stack) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->llama-stack) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->llama-stack) (0.25.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit->llama-stack) (0.2.13)\n","Collecting ecdsa!=0.15 (from python-jose->llama-stack)\n","  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from python-jose->llama-stack) (4.9.1)\n","Requirement already satisfied: pyasn1>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from python-jose->llama-stack) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->llama-stack) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->llama-stack) (2.4.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->llama-stack) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->llama-stack) (2.19.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->llama-stack) (2024.11.6)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa!=0.15->python-jose->llama-stack) (1.17.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.10->llama-stack) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.10->llama-stack) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.10->llama-stack) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-stack-client>=0.2.10->llama-stack) (2025.2)\n","Downloading llama_stack-0.2.10.1-py3-none-any.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_stack_client-0.2.10-py3-none-any.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.6/307.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading python_jose-3.5.0-py2.py3-none-any.whl (34 kB)\n","Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=7efa078b50f9e0abfcb57dc164733efd067262c9d4b0904ccb6df7739c7afda6\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","Successfully built fire\n","Installing collected packages: python-dotenv, pyaml, fire, ecdsa, python-jose, llama-stack-client, llama-stack\n","Successfully installed ecdsa-0.19.1 fire-0.7.0 llama-stack-0.2.10.1 llama-stack-client-0.2.10 pyaml-25.5.0 python-dotenv-1.1.0 python-jose-3.5.0\n","Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m287.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n","  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting numpy>=1.20.0 (from llama-cpp-python)\n","  Downloading numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m146.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Collecting jinja2>=2.11.3 (from llama-cpp-python)\n","  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n","Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n","  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m274.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m212.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m268.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n","Building wheels for collected packages: llama-cpp-python\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for llama-cpp-python \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for llama-cpp-python\u001b[0m\u001b[31m\n","\u001b[0mFailed to build llama-cpp-python\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (llama-cpp-python)\u001b[0m\u001b[31m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","build-essential is already the newest version (12.9ubuntu3).\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"]}],"source":["!pip install llama-stack -U\n","!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir\n","!apt-get install -y cmake build-essential"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3689,"status":"ok","timestamp":1750097473753,"user":{"displayName":"Nandoo","userId":"07661495182627101655"},"user_tz":-120},"id":"ICDGjSBmwoE_","outputId":"d465fbd6-589f-46d6-fefc-de3cfe9d3420"},"outputs":[{"output_type":"stream","name":"stdout","text":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mModel Descriptor(ID)        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mHugging Face Repo           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mContext Length\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-2-7b                  \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-2-7b       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-2-13b                 \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-2-13b      \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-2-70b                 \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-2-70b      \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-2-7b-chat             \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-2-7b-chat  \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-2-13b-chat            \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-2-13b-chat \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-2-70b-chat            \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-2-70b-chat \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-3-8B                  \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3-8B       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-3-70B                 \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3-70B      \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-3-8B-Instruct         \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3-8B-Instr…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-3-70B-Instruct        \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3-70B-Inst…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-8B                 \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-8B     \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-70B                \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-70B    \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-405B:bf16-mp8      \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-405B   \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-405B               \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-405B-F…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-405B:bf16-mp16     \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-405B   \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-8B-Instruct        \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-8B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-70B-Instruct       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-70B-In…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-405B-Instruct:bf16…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-405B-I…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-405B-Instruct      \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-405B-I…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.1-405B-Instruct:bf16…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.1-405B-I…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-1B                 \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-1B     \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-3B                 \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-3B     \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-11B-Vision         \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-11B-Vi…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-90B-Vision         \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-90B-Vi…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-1B-Instruct        \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-1B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-3B-Instruct        \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-3B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-1B-Instruct:int4-q…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-1B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-1B-Instruct:int4-s…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-1B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-3B-Instruct:int4-q…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-3B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-3B-Instruct:int4-s…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-3B-Ins…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-11B-Vision-Instruct\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-11B-Vi…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.2-90B-Vision-Instruct\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.2-90B-Vi…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama3.3-70B-Instruct       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-3.3-70B-In…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-4-Scout-17B-16E       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-4-Scout-17…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m256K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-4-Maverick-17B-128E   \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-4-Maverick…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m256K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-4-Scout-17B-16E-Instr…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-4-Scout-17…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m10240K        \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-4-Maverick-17B-128E-I…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-4-Maverick…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m1024K         \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-4-Maverick-17B-128E-I…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-4-Maverick…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m1024K         \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-4-12B           \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-4-12B\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m8K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-3-11B-Vision    \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-3-11…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-3-1B:int4       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-3-1B…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-3-1B            \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-3-1B \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-3-8B            \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-3-8B \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-3-8B:int8       \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-3-8B…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m128K          \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Guard-2-8B            \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Guard-2-8B \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m4K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mPrompt-Guard-86M            \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Prompt-Guard-86M \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m0K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Prompt-Guard-2-86M    \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Prompt-Gua…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m0K            \u001b[0m\u001b[1;37m \u001b[0m│\n","├──────────────────────────────┼──────────────────────────────┼────────────────┤\n","│\u001b[1;37m \u001b[0m\u001b[1;37mLlama-Prompt-Guard-2-22M    \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37mmeta-llama/Llama-Prompt-Gua…\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;37m \u001b[0m\u001b[1;37m0K            \u001b[0m\u001b[1;37m \u001b[0m│\n","└──────────────────────────────┴──────────────────────────────┴────────────────┘\n"]}],"source":["!llama model list --show-all"]},{"cell_type":"markdown","metadata":{"id":"eR_oxqBgyDI_"},"source":["Convertir de .pth a gguf"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":593216,"status":"ok","timestamp":1750098066973,"user":{"displayName":"Nandoo","userId":"07661495182627101655"},"user_tz":-120},"id":"0nNtpN--5dLp","outputId":"4aa1dc34-811e-4be2-a46a-e577e0bf5510"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide the signed URL for model Llama3.2-3B-Instruct you received via email after visiting https://www.llama.com/llama-downloads/ (e.g., https://llama3-1.llamameta.net/*?Policy...): object address  : 0x7e4205d9efe0\n","object refcount : 2\n","object type     : 0x9d7580\n","object type name: KeyboardInterrupt\n","object repr     : KeyboardInterrupt()\n","lost sys.stderr\n","^C\n","cp: cannot stat '/root/.llama/checkpoints/Llama3.2-3B-Instruct/*': No such file or directory\n"]}],"source":["# Paso 1: Instalar herramientas necesarias\n","!pip install -q llama-stack transformers sentencepiece\n","\n","# Paso 2: Descargar el modelo desde Meta (solo si no lo tienes ya)\n","!llama model download --source meta --model-id Llama3.2-3B-Instruct\n","\n","# Paso 3: Preparar los archivos del modelo para trabajar con ellos\n","!mkdir -p /content/models/Llama3.2-3B-Instruct\n","!cp /root/.llama/checkpoints/Llama3.2-3B-Instruct/* /content/models/Llama3.2-3B-Instruct/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDhAxSlpyQmF"},"outputs":[],"source":["# Paso 4: Clonar llama.cpp y compilarlo\n","%cd /content\n","!git clone https://github.com/ggerganov/llama.cpp.git\n","%cd llama.cpp\n","!cmake -S . -B build\n","!cmake --build build"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8Pu4h_XyaV4"},"outputs":[],"source":["# Paso 5: Convertir el modelo .pth al formato Hugging Face\n","!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/llama/convert_llama_weights_to_hf.py\n","\n","!python3 convert_llama_weights_to_hf.py \\\n","  --input_dir /content/models/Llama3.2-3B-Instruct \\\n","  --model_size 3B \\\n","  --output_dir /content/models/Llama3.2-3B-Instruct-HF \\\n","  --llama_version 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RGet4SB9jny"},"outputs":[],"source":["!ls -lh /content/models/Llama3.2-3B-Instruct-HF/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0d9hLqkB9rX1"},"outputs":[],"source":["!wget https://raw.githubusercontent.com/ggerganov/llama.cpp/master/convert_hf_to_gguf.py -O convert_hf_to_gguf.py\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkXRRb60-KdA"},"outputs":[],"source":["!python3 convert_hf_to_gguf.py \\\n","  /content/models/Llama3.2-3B-Instruct-HF \\\n","  --outfile /content/models/Llama3.2-3B-Instruct/llama-3.2b-instruct.gguf \\\n","  --outtype f16\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0FO1HKtlvVP"},"outputs":[],"source":["!pip install llama-cpp-python==0.2.61 gradio --quiet\n","!pip uninstall -y llama-cpp-python\n","!pip install llama-cpp-python --extra-index-url=https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/avx2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKVWehQxpwiq"},"outputs":[],"source":["from llama_cpp import Llama\n","import gradio as gr\n","\n","# Ruta al modelo\n","MODEL_PATH = \"/content/models/Llama3.2-3B-Instruct/llama-3.2b-instruct.gguf\"\n","\n","# Cargar el modelo\n","#llm = Llama(\n"," #   model_path=MODEL_PATH,\n"," #   n_ctx=4096,\n","  #  n_threads=8,  # Puedes bajar a 4 si va lento\n","   # n_gpu_layers=35  # Usa la GPU si tienes activado aceleración\n","#)\n","llm = Llama(\n","    model_path=MODEL_PATH,\n","    n_ctx=2048,          # Menos contexto = menos memoria\n","    n_threads=4,         # Reduce hilos para no saturar CPU\n","    n_gpu_layers=26      # Baja a 20 si estás en GPU pequeña (o 0 si estás sin GPU)\n",")\n","\n","# Función de respuesta\n","def responder(mensaje, historia):\n","    prompt = f\"{mensaje}\\nAssistant:\"\n","    respuesta = llm(prompt, max_tokens=256, stop=[\"\\n\", \"</s>\"])\n","    texto = respuesta[\"choices\"][0][\"text\"].strip()\n","    historia.append((mensaje, texto))\n","    return historia, historia\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9TG7i-M9qgc1"},"outputs":[],"source":["# Interfaz tipo chat\n","chatbot = gr.ChatInterface(\n","    fn=responder,\n","    title=\"Asistente LLaMA 3.2 3B Instruct\",\n","    chatbot=gr.Chatbot(),\n","    textbox=gr.Textbox(placeholder=\"Haz una pregunta...\", lines=2),\n","    examples=[\"¿Qué es la computación cuántica?\", \"Explícame la Segunda Guerra Mundial\"],\n","    cache_examples=False\n",")\n","\n","# Ejecutar la app\n","chatbot.launch()"]},{"cell_type":"markdown","metadata":{"id":"OjH_SLaogDL-"},"source":["___________________________________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvwPJRLmqhhC"},"outputs":[],"source":["from llama_cpp import Llama\n","\n","llm = Llama(\n","    model_path=\"/content/models/Llama3.2-3B-Instruct/llama-3.2b-instruct.gguf\",\n","    n_ctx=2048,\n","    n_threads=4,\n","    n_gpu_layers=26  # Usa GPU para las primeras 26 capas\n",")\n","\n","output = llm(\"Dime una curiosidad sobre Marte.\", max_tokens=64)\n","print(output[\"choices\"][0][\"text\"])\n"]},{"cell_type":"markdown","metadata":{"id":"sTCRhKztcKw3"},"source":["--------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0zFn63HcJuQ"},"outputs":[],"source":["# -----------------------------------------\n","# INSTALAR DEPENDENCIAS Y PREPARAR ENTORNO\n","# -----------------------------------------\n","!apt-get -y install cmake build-essential\n","!pip install -q llama-stack transformers sentencepiece\n","!pip install -q llama-cpp-python==0.2.61 gradio\n","!pip uninstall -y llama-cpp-python\n","!pip install llama-cpp-python --extra-index-url=https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/avx2\n","\n","# -----------------------------------------\n","# DESCARGAR Y PREPARAR MODELO\n","# -----------------------------------------\n","!llama model download --source meta --model-id Llama3.2-3B-Instruct\n","\n","!mkdir -p /content/models/Llama3.2-3B-Instruct\n","!cp /root/.llama/checkpoints/Llama3.2-3B-Instruct/* /content/models/Llama3.2-3B-Instruct/\n","\n","# -----------------------------------------\n","# CONVERTIR A FORMATO HUGGING FACE\n","# -----------------------------------------\n","!cd /content && git clone https://github.com/ggerganov/llama.cpp.git\n","!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/llama/convert_llama_weights_to_hf.py\n","\n","!python3 convert_llama_weights_to_hf.py \\\n","  --input_dir /content/models/Llama3.2-3B-Instruct \\\n","  --model_size 3B \\\n","  --output_dir /content/models/Llama3.2-3B-Instruct-HF \\\n","  --llama_version 3\n","\n","# -----------------------------------------\n","# CONVERTIR A GGUF\n","# -----------------------------------------\n","!wget https://raw.githubusercontent.com/ggerganov/llama.cpp/master/convert_hf_to_gguf.py -O convert_hf_to_gguf.py\n","\n","!python3 convert_hf_to_gguf.py \\\n","  /content/models/Llama3.2-3B-Instruct-HF \\\n","  --outfile /content/models/Llama3.2-3B-Instruct/llama-3.2b-instruct.gguf \\\n","  --outtype f16\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CebPc1HxiMRB"},"outputs":[],"source":["from llama_cpp import Llama\n","\n","llm = Llama(\n","    model_path=\"/content/models/Llama3.2-3B-Instruct/llama-3.2b-instruct.gguf\",\n","    n_ctx=1024,\n","    n_threads=4,\n","    n_gpu_layers=0  # 0 = todo en CPU (para confirmar si el fallo es GPU)\n",")\n","\n","respuesta = llm(\"¿Cuál es la capital de Japón?\", max_tokens=64)\n","print(respuesta[\"choices\"][0][\"text\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRNl_ElWcYfx"},"outputs":[],"source":["from llama_cpp import Llama\n","\n","llm = Llama(\n","    model_path=\"/content/models/Llama3.2-3B-Instruct/llama-3.2b-instruct.gguf\",\n","    n_ctx=2048,\n","    n_threads=4,\n","    n_gpu_layers=28  # Full GPU para modelo 3B en Colab T4\n",")\n","\n","output = llm(\"Dime una curiosidad sobre Marte.\", max_tokens=64)\n","print(\"Respuesta:\", output[\"choices\"][0][\"text\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVuGfKFohYBi"},"outputs":[],"source":["output = llm(\"¿Cuál es la capital de Italia?\", max_tokens=32)\n","print(output[\"choices\"][0][\"text\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDFS0lIzcbTZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNlICBLJMLZnimBN63r+YMw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}